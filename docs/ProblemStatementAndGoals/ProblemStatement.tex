\documentclass{article}

\usepackage{tabularx}
\usepackage{booktabs}

\title{Problem Statement and Goals\\\progname}

\author{\authname}

\date{}

\input{../Comments}
\input{../Common}

\begin{document}

\maketitle

\begin{table}[hp]
\caption{Revision History} \label{TblRevisionHistory}
\begin{tabularx}{\textwidth}{llX}
\toprule
\textbf{Date} & \textbf{Developer(s)} & \textbf{Change}\\
\midrule
September 24, 2024 & Harman Bassi and Kyen So & Initial Draft\\
\bottomrule
\end{tabularx}
\end{table}

\newpage

\section{Problem Statement}

\subsection{Problem}
Our team aims to design a software that can reliably detect a person’s body from Point Cloud Data (PCD) even if they are blocked by another person or other objects, which existing solutions cannot reliably do so. This new technology would have a multitude of uses, of which we are particularly interested with assistive robots. These robots could be used anywhere from crisis relief efforts to household tasks. Using its ability to detect people, even when partially hidden, they would be able to perform tasks ranging from pulling people from rubble to providing household services. 

\subsection{Inputs and Outputs}
The software will have the input of .pcd (point cloud data) files. These files can either be uploaded directly, i.e. in an "offline" manner, or supplied in a constant stream live through a Kinect sensor. Our application will output a visual representation of the point cloud data, highlighting the space that the person we identified occupies, as well as the hidden 3D space that we predict/estimate they could be occupying based on the acquired information. Colored boxes will be used to highlight this space estimation.


\subsection{Stakeholders}
Dr.Gary Bone wishes to create a solution for robots to recognize their surroundings and identify the spaces that are occupied by the people around them. This way, these assistive robots can be used to help people at their homes.\\

Humanitarian Aid Organizations could also use this solution to help discover humans trapped/hidden during distarious scenarios (i.e. Earthquakes, Building Collapse) that may need assistance getting out.\\

Robot Manufacturers could implement the solution into robots to provide them with better spatial awareness when working in an environment with humans.

\subsection{Environment}
The software must work in conjunction with the Microsoft Kinect in real-time. Additionally, the software will be designed to work in the Windows operating system. Regarding languages and libraries, we are planning on writing this application in C++ to ensure the ability to keep processing time/complexity low. Further, since we our inputs are point cloud data files, we will likely be using PCL (point cloud library) to manipulate the data. Finally, we will potentially utilize OpenCV as our project has a heavy computer vision component.

\newpage
\section{Goals}   

\subsection{Identifying a Person}
The application should be able to identify a human within a variety of different environments. This includes detecting the human even if they are partially obscured by an object.

\subsection{Real-time Processing}
The application needs to be able to process the data and constantly be updating to see if a human is detected within frame. The reading and processing of the data needs to be done with minimal latency.

\subsection{Location Prediction}
The application should to be able to predict the space a potentially partially obscured person occupies based on the detected portion. This estimation should be displayed to the user.

\subsection{Usability}
The application should be easy to navigate and use. Setup instructions should be easily accessed and use of the application should come with proper instructions, making it uncomplicated and straightforward to interface with.

\subsection{Analyze and Process offline PCD files}
The application should be able to take uploaded Point Cloud Data files as an input rather than analyzing captured data in real-time. This allows for the testing of various controlled scenarios to ensure that the program can successfully identify a human in different scenarios. Outputs of the application can be easily compared to the expected results of the configured scenario to determine accuracy.
        
\newpage
\section{Stretch Goals}

\subsection{Mapping the environment}
The application should be able to identify other objects that are present within the environment. Having a better understanding of the environment means that the application would provide better spatial awareness by disregarding objects as being possible body parts.

\subsection{Drawing a Humanoid Outline}
The application should be able to create a realistic outline with humanoid features for the people it identifies. A more accurate outline provides greater dimension and distinction between what is and isn’t part of the human body. This would allow for a more accurate detection and human depiction.
  
\subsection{Model Identified Person using Shapes}
The application should be able to provide a rough model based on where it believes the person is in 3D space. A rough shape of the head, torso, and limbs will be shown on the screen to help provide an accurate location of the human on screen.

\subsection{Location Precision}
The application is able to provide the spatial coordinate of the person. This would help with visualizing the human within a 3D space and provide the robot with a better understanding of where the person is from its current location.

\section{Challenge Level and Extras}

The challenge level of this project is currently set to Advanced/Research level. The project consists of topics 
that aren't covered within previous year courses, and the majority of the project doesn't fit into the group's current domain knowledge on computer vision and point cloud data manipulation. 
There is a learning curve with the computer vision aspect of the program, as we will have to quickly learn and apply libraries and techniques that are novel to us. As our project is advanced, the only extra will be a research manual.


\newpage{}

\section*{Appendix --- Reflection}

\input{../Reflection.tex}   

\end{document}